{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importações"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import math\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas_datareader as data_reader\r\n",
    "from pandas.util.testing import assert_frame_equal #import alterado\r\n",
    "\r\n",
    "from tqdm import tqdm_notebook, tqdm\r\n",
    "from collections import deque"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7eea41f82daf>:8: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal #import alterado\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "tf.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class IA_Trader():\r\n",
    "    \"\"\"\r\n",
    "    state_size = estados que estão vindo do ambiente, por exemplo os sensores de\r\n",
    "     um carro autônomo. Seria a camada de entrada da rede neural.\r\n",
    "\r\n",
    "    action_space = indica o numero de ações que o algoritmo pode tomar, ou seja,\r\n",
    "    suas escolhas. Comprar, vender, ou não fazer nada.\r\n",
    "\r\n",
    "    model_name = Nome do modelo de aprendizagem.\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, state_size, action_space = 3, model_name=\"IATrader\"):\r\n",
    "        self.state_size = state_size\r\n",
    "        self.action_space = action_space\r\n",
    "        # memmoria de 2000 ações, ou seja, o modelo não precisa ficar treinando algumas etapas repetitivas\r\n",
    "        self.memory = deque(maxlen = 2000)\r\n",
    "        #memoria da experiencia de replay\r\n",
    "        self.model_name = model_name\r\n",
    "\r\n",
    "        #gama da equação de bellmam = fator de desconto\r\n",
    "        self.gamma = 0.95\r\n",
    "\r\n",
    "        #indica se as ações serão tomadas randomicamente ou pela rede neural. Sendo 1.0 = 100% randomico\r\n",
    "        self.epsilon = 1.0\r\n",
    "\r\n",
    "        #porcentegem do modelo tomar uma ação randomica, ou seja, com o valor de 0.1 o \r\n",
    "        #agente tem 10% de chance de tomar uma ação randomica e fazer ele explorar mais o ambiente.\r\n",
    "        self.epsilon_final = 0.01\r\n",
    "\r\n",
    "        #variavel responsável por decrementar o valor de epsilon, para poder fazer o ajuste do peso da rede.\r\n",
    "        self.epsilon_decay = 0.995\r\n",
    "\r\n",
    "        #criando o modelo quando o objeto é chamado\r\n",
    "        self.model = self.model_builder();\r\n",
    "\r\n",
    "    #construção da rede neural\r\n",
    "    def model_builder(self):\r\n",
    "        model = tf.keras.models.Sequential()\r\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation='relu', input_dim=self.state_size))\r\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation='relu'))\r\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation='relu'))\r\n",
    "        model.add(tf.keras.layers.Dense(units=self.action_space, activation='linear')) #linear retorna todos os voleres dos neurônios\r\n",
    "        model.compile(loss='mse', optimizer = tf.keras.optimizers.Adam(learning_rate=0.001))\r\n",
    "        return model\r\n",
    "\r\n",
    "    #função que irá fazer toda a negociação, ou seja, as ações que serão tomadas\r\n",
    "    def trade(self, state):\r\n",
    "        #função que irá tomar uma decisão aleatória no ambiente caso o valor passado pela função random for menor que a de epsilon, possibilitando a exploração do ambiente\r\n",
    "        if random.random() <= self.epsilon:\r\n",
    "            return random.randrange(self.action_space)\r\n",
    "\r\n",
    "        #caso a ação tomada não for aleatória, ou seja, não acionando a condicional anterior, os valores serão buscados por meio da rede neural\r\n",
    "        actions = self.model.predict(state)\r\n",
    "        #retorna o maior valor dita pela neural\r\n",
    "        return np.argmax(actions[0])\r\n",
    "    \r\n",
    "    #seleciona um grupo de dados para fazer o treinamento\r\n",
    "    def batch_train(self, batch_size):\r\n",
    "        batch = []\r\n",
    "\r\n",
    "        #pegando somente as amostra do final da memória. Pois fica sem sentido, no caso das ações, pegar uma ação aleatória de 2005 e usar para prever outra em 2020\r\n",
    "        for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\r\n",
    "            batch.append(self.memory[i])\r\n",
    "\r\n",
    "        for state, action, reward, next_state, done in batch:\r\n",
    "            if not done:\r\n",
    "                reward = reward + self.gamma * np.amax(self.model.predict(np.asarray(next_state))[0]) #pega os valores de Q para o prox estado\r\n",
    "\r\n",
    "            #pegando os valores de Q para o estado atual\r\n",
    "            target = self.model.predict(state)\r\n",
    "            #Adicionando uma recompensa para a ação, onde a coluna [action] recebe o valor dessa recompensa.\r\n",
    "            target[0][action] = reward\r\n",
    "\r\n",
    "            self.model.fit(state, target, epochs=1, verbose = 0)\r\n",
    "\r\n",
    "        #Atualizando o epislon, caso ele for maior que o [epsilon_final]\r\n",
    "        if self.epsilon > self.epsilon_final:\r\n",
    "            self.epsilon *= self.epsilon_decay\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Equação de belmam utilizada para calcular a recompensa\r\n",
    "\r\n",
    "# $$V(s) = max_{a}(R(s, a)) + \\gamma V(s')) | $$\r\n",
    "\r\n",
    "# $$\\gamma = 0.9 $$\r\n",
    "\r\n",
    "\r\n",
    "Parte utilizada na recompensa consiste:\r\n",
    "# $$ R(s, a)) + \\gamma V(s') $$\r\n",
    "\r\n",
    "onde $R(s, a)$ = reward = recompensa no estado atual;\r\n",
    "\r\n",
    "$ \\gamma V(s') $ = self.gamma * np.amax(self.model.predict(next_state)[0])\r\n",
    "\r\n",
    "$ s' $ = proximo estado.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sigmoid\r\n",
    "\r\n",
    "## $ y = \\frac{1}{1 + e^{-x}} $"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def sigmoid(x):\r\n",
    "    return 1 / (1 + math.exp(-x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def stocks_price_format(n):\r\n",
    "    if n < 0:\r\n",
    "        #caso for um valor negativo, adiciona o menos antes do preço($)\r\n",
    "        return \"- $ {0:2f}\".format(abs(n))\r\n",
    "    else:\r\n",
    "        #se não fica sem o menos\r\n",
    "        return \"$ {0:2f}\".format(abs(n))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dataset = data_reader.DataReader(\"AAPL\", data_source = \"yahoo\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "dataset.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>27.075001</td>\n",
       "      <td>26.877501</td>\n",
       "      <td>26.9750</td>\n",
       "      <td>26.924999</td>\n",
       "      <td>107521600.0</td>\n",
       "      <td>25.251354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-07</th>\n",
       "      <td>27.190001</td>\n",
       "      <td>26.767500</td>\n",
       "      <td>26.9575</td>\n",
       "      <td>27.090000</td>\n",
       "      <td>169457200.0</td>\n",
       "      <td>25.406099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-08</th>\n",
       "      <td>26.817499</td>\n",
       "      <td>26.309999</td>\n",
       "      <td>26.8125</td>\n",
       "      <td>26.379999</td>\n",
       "      <td>212008000.0</td>\n",
       "      <td>24.740232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-09</th>\n",
       "      <td>26.430000</td>\n",
       "      <td>25.782499</td>\n",
       "      <td>26.1600</td>\n",
       "      <td>25.782499</td>\n",
       "      <td>186228000.0</td>\n",
       "      <td>24.179869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-12</th>\n",
       "      <td>26.430000</td>\n",
       "      <td>25.632500</td>\n",
       "      <td>25.6625</td>\n",
       "      <td>26.360001</td>\n",
       "      <td>181171200.0</td>\n",
       "      <td>24.721476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 High        Low     Open      Close       Volume  Adj Close\n",
       "Date                                                                        \n",
       "2016-09-06  27.075001  26.877501  26.9750  26.924999  107521600.0  25.251354\n",
       "2016-09-07  27.190001  26.767500  26.9575  27.090000  169457200.0  25.406099\n",
       "2016-09-08  26.817499  26.309999  26.8125  26.379999  212008000.0  24.740232\n",
       "2016-09-09  26.430000  25.782499  26.1600  25.782499  186228000.0  24.179869\n",
       "2016-09-12  26.430000  25.632500  25.6625  26.360001  181171200.0  24.721476"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "str(dataset.index[0]).split()[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2016-09-06'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def dataset_loader(stock_name):\r\n",
    "    #lendo o dataset, onde busca-se pela ação [stock_name] na base de dados do yahoo\r\n",
    "    dataset = data_reader.DataReader(stock_name, data_source = \"yahoo\")\r\n",
    "    #data de inicio da ação. Pode ser também em um periodo específico\r\n",
    "    start_date = str(dataset.index[0]).split()[0]\r\n",
    "    #ultima data da ação coletada\r\n",
    "    end_date = str(dataset.index[-1]).split()[0]\r\n",
    "    #preço de fechamento da ação no dia\r\n",
    "    close = dataset['Close']\r\n",
    "    return close"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def state_creator(data, timestep, window_size):\r\n",
    "    \"\"\"\r\n",
    "    Função onde pega os dados da base de dados de acordo com o timestep (episodios do treinamento)\r\n",
    "    e widow_size (tamanho do janelamento dos dados)\r\n",
    "    \r\n",
    "    \"\"\"\r\n",
    "    starting_id = timestep - window_size + 1\r\n",
    "  \r\n",
    "    if starting_id >= 0:\r\n",
    "        # se o indice da ação for maior do que 0, então ele pega os valores de acordo com o window_size\r\n",
    "        windowed_data = data[starting_id:timestep + 1]\r\n",
    "    else:\r\n",
    "        # se caso o index for 0, ele replica o mesmo valor de acordo com o tamanho do window_size\r\n",
    "        windowed_data = - starting_id * [data[0]] + list(data[0:timestep + 1])\r\n",
    "    \r\n",
    "    state = []\r\n",
    "    for i in range(window_size - 1):\r\n",
    "        # normalização dos valores atraves da função da sigmoid = valores entre 0 e 1\r\n",
    "        state.append(sigmoid(windowed_data[i + 1] - windowed_data[i]))\r\n",
    "    \r\n",
    "    return np.array([state])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "stock_name = \"AAPL\"\r\n",
    "data = dataset_loader(stock_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "state_creator(data, 20, 5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.39114563, 0.55416182, 0.46692298, 0.52996426]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "window_size = 10\r\n",
    "episodes = 10\r\n",
    "batch_size = 32\r\n",
    "data_samples = len(data) - 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "data_samples"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "trader = IA_Trader(window_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "trader.model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 11,171\n",
      "Trainable params: 11,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "for episode in range(1, episodes + 1):\r\n",
    "    print(\"Episode: {}/{}\".format(episode, episodes))\r\n",
    "    #criando os estados com 10 valores, sendo o [window_size =- 1], então para 10 valores adiciona +1\r\n",
    "    # começando com a primeira posição do dataset = 0   \r\n",
    "    state = state_creator(data, 0, window_size + 1)\r\n",
    "    #total de lucros com a compra\r\n",
    "    total_profit = 0\r\n",
    "    #armazena todas as ações que será comprada\r\n",
    "    trader.inventory = []\r\n",
    "\r\n",
    "    # percorrendo a base de dados \r\n",
    "    for t in tqdm_notebook(range(data_samples)):\r\n",
    "        # ação que será tomada\r\n",
    "        action = trader.trade(state)\r\n",
    "        # cálculo da próxima ação\r\n",
    "        next_state = state_creator(data, t + 1, window_size + 1)\r\n",
    "        # inicialização das recompensas\r\n",
    "        reward = 0\r\n",
    "\r\n",
    "        # Comprando uma ação se for 1\r\n",
    "        if action == 1: \r\n",
    "            # guardando os valores  \r\n",
    "            trader.inventory.append(data[t])\r\n",
    "            print(\"AI Trader bought: \", stocks_price_format(data[t]))\r\n",
    "\r\n",
    "        # Vendendo acao se for 2 e verifica se já foi comprado alguma ação\r\n",
    "        elif action == 2 and len(trader.inventory) > 0:\r\n",
    "            # retira a ação e passa para a variavel  \r\n",
    "            buy_price = trader.inventory.pop(0)\r\n",
    "            \r\n",
    "            # calculo da recompensa, onde é definida pelo valor da venda menos o valor comprado, se for negativo, retorna 0 = sem recompensa\r\n",
    "            reward = max(data[t] - buy_price, 0)\r\n",
    "            # cálculo do lucro  \r\n",
    "            total_profit += data[t] - buy_price\r\n",
    "            print(\"AI Trader sold: \", stocks_price_format(data[t]), \" Profit: \" + stocks_price_format(data[t] - buy_price))\r\n",
    "            \r\n",
    "        # significa que está no ultimo dado da base de dado\r\n",
    "        if t == data_samples - 1:\r\n",
    "            done = True\r\n",
    "        else:\r\n",
    "            done = False\r\n",
    "\r\n",
    "        # armazenando na memoria os dados\r\n",
    "        trader.memory.append((state, action, reward, next_state, done))\r\n",
    "\r\n",
    "        # passando para o proximo estado\r\n",
    "        state = next_state\r\n",
    "\r\n",
    "        if done:\r\n",
    "            print(\"########################\")\r\n",
    "            print(\"Total profit: {}\".format(total_profit))\r\n",
    "            print(\"########################\")\r\n",
    "\r\n",
    "        # quando o tamanho da memoria for maior que o batch size, faz-se o treinamento do modelo\r\n",
    "        if len(trader.memory) > batch_size:\r\n",
    "            trader.batch_train(batch_size)\r\n",
    "     \r\n",
    "    # salvando o modelo a cada 10 episodios\r\n",
    "    if episode % 10 == 0:\r\n",
    "        trader.model.save(\"ai_trader_{}.h5\".format(episode))\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Episode: 1/10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-18-370a49742593>:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for t in tqdm_notebook(range(data_samples)):\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c059b3d73244fe99c3f7ce6d5b5f85a"
      },
      "text/plain": [
       "  0%|          | 0/1258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AI Trader bought:  $ 26.924999\n",
      "AI Trader sold:  $ 27.090000  Profit: $ 0.165001\n",
      "AI Trader bought:  $ 26.360001\n",
      "AI Trader bought:  $ 28.892500\n",
      "AI Trader sold:  $ 28.395000  Profit: $ 2.035000\n",
      "AI Trader bought:  $ 28.392500\n",
      "AI Trader bought:  $ 28.387501\n",
      "AI Trader sold:  $ 28.655001  Profit: - $ 0.237499\n",
      "AI Trader bought:  $ 28.177500\n",
      "AI Trader sold:  $ 28.129999  Profit: - $ 0.262501\n",
      "AI Trader bought:  $ 28.250000\n",
      "AI Trader bought:  $ 28.262501\n",
      "AI Trader sold:  $ 28.472500  Profit: $ 0.084999\n",
      "AI Trader sold:  $ 28.514999  Profit: $ 0.337500\n",
      "AI Trader sold:  $ 29.012501  Profit: $ 0.762501\n",
      "AI Trader bought:  $ 29.075001\n",
      "AI Trader bought:  $ 29.334999\n",
      "AI Trader bought:  $ 29.245001\n",
      "AI Trader sold:  $ 29.367500  Profit: $ 1.105000\n",
      "AI Trader bought:  $ 29.264999\n",
      "AI Trader bought:  $ 29.412500\n",
      "AI Trader sold:  $ 29.562500  Profit: $ 0.487499\n",
      "AI Trader sold:  $ 28.620001  Profit: - $ 0.714998\n",
      "AI Trader bought:  $ 28.430000\n",
      "AI Trader bought:  $ 27.897499\n",
      "AI Trader bought:  $ 27.457500\n",
      "AI Trader bought:  $ 27.209999\n",
      "AI Trader sold:  $ 27.602501  Profit: - $ 1.642500\n",
      "AI Trader sold:  $ 27.719999  Profit: - $ 1.545000\n",
      "AI Trader sold:  $ 27.107500  Profit: - $ 2.305000\n",
      "AI Trader bought:  $ 26.427500\n",
      "AI Trader bought:  $ 26.777500\n",
      "AI Trader sold:  $ 27.497499  Profit: - $ 0.932501\n",
      "AI Trader sold:  $ 27.514999  Profit: - $ 0.382500\n",
      "AI Trader sold:  $ 27.932501  Profit: $ 0.475000\n",
      "AI Trader sold:  $ 27.807501  Profit: $ 0.597502\n",
      "AI Trader sold:  $ 27.947500  Profit: $ 1.520000\n",
      "AI Trader sold:  $ 27.892500  Profit: $ 1.115000\n",
      "AI Trader bought:  $ 27.475000\n",
      "AI Trader sold:  $ 27.277500  Profit: - $ 0.197500\n",
      "AI Trader bought:  $ 27.487499\n",
      "AI Trader sold:  $ 28.487499  Profit: $ 1.000000\n",
      "AI Trader bought:  $ 28.797501\n",
      "AI Trader sold:  $ 28.955000  Profit: $ 0.157499\n",
      "AI Trader bought:  $ 29.315001\n",
      "AI Trader sold:  $ 29.190001  Profit: - $ 0.125000\n",
      "AI Trader bought:  $ 29.477501\n",
      "AI Trader sold:  $ 29.747499  Profit: $ 0.269999\n",
      "AI Trader bought:  $ 30.000000\n",
      "AI Trader bought:  $ 29.945000\n",
      "AI Trader sold:  $ 30.020000  Profit: $ 0.020000\n",
      "AI Trader sold:  $ 29.992500  Profit: $ 0.047501\n",
      "AI Trader bought:  $ 30.487499\n",
      "AI Trader bought:  $ 30.407499\n",
      "AI Trader sold:  $ 32.187500  Profit: $ 1.700001\n",
      "AI Trader bought:  $ 32.132500\n",
      "AI Trader sold:  $ 32.270000  Profit: $ 1.862501\n",
      "AI Trader sold:  $ 32.572498  Profit: $ 0.439999\n",
      "AI Trader bought:  $ 33.322498\n",
      "AI Trader sold:  $ 33.755001  Profit: $ 0.432503\n",
      "AI Trader bought:  $ 34.174999\n",
      "AI Trader bought:  $ 34.132500\n",
      "AI Trader sold:  $ 34.165001  Profit: - $ 0.009998\n",
      "AI Trader bought:  $ 34.232498\n",
      "AI Trader sold:  $ 34.247501  Profit: $ 0.115002\n",
      "AI Trader sold:  $ 34.740002  Profit: $ 0.507504\n",
      "AI Trader bought:  $ 34.834999\n",
      "AI Trader sold:  $ 34.880001  Profit: $ 0.045002\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   3872\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3873\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op_def_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3874\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Placeholder'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-370a49742593>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m# quando o tamanho da memoria for maior que o batch size, faz-se o treinamento do modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mtrader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# salvando o modelo a cada 10 episodios\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e3c0e68e40a7>\u001b[0m in \u001b[0;36mbatch_train\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pega os valores de Q para o prox estado\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m#pegando os valores de Q para o estado atual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1567\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1569\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1570\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1571\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[1;34m(self, map_func)\u001b[0m\n\u001b[0;32m   1725\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m     \"\"\"\n\u001b[1;32m-> 1727\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m   def interleave(self,\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[0;32m   4120\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4121\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4122\u001b[1;33m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   4123\u001b[0m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0;32m   4124\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3369\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3370\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3371\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3373\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2936\u001b[0m       \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m     \"\"\"\n\u001b[1;32m-> 2938\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   2939\u001b[0m         *args, **kwargs)\n\u001b[0;32m   2940\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2904\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2906\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2907\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2908\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    900\u001b[0m       \u001b[0marg_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m       \u001b[0mkwarg_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 902\u001b[1;33m     func_args = _get_defun_inputs_from_args(\n\u001b[0m\u001b[0;32m    903\u001b[0m         args, arg_names, flat_shapes=arg_shapes)\n\u001b[0;32m    904\u001b[0m     func_kwargs = _get_defun_inputs_from_kwargs(\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_get_defun_inputs_from_args\u001b[1;34m(args, names, flat_shapes)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_defun_inputs_from_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;34m\"\"\"Maps Python function positional args to graph-construction inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m   return _get_defun_inputs(\n\u001b[0m\u001b[0;32m   1139\u001b[0m       args, names, structure=args, flat_shapes=flat_shapes)\n\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_get_defun_inputs\u001b[1;34m(args, names, structure, flat_shapes)\u001b[0m\n\u001b[0;32m   1208\u001b[0m         \u001b[0mplaceholder_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1210\u001b[1;33m           placeholder = graph_placeholder(\n\u001b[0m\u001b[0;32m   1211\u001b[0m               \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaceholder_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m               name=requested_name)\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m     36\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m     39\u001b[0m       \u001b[1;34m\"Placeholder\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m       attrs=attrs, name=name)\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m       \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         compute_device)\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3475\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3476\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3477\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3478\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3479\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1971\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1972\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1973\u001b[1;33m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1974\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m   1975\u001b[0m                                 control_input_ops, op_def)\n",
      "\u001b[1;32mD:\\Programns\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   3875\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3876\u001b[0m         \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3877\u001b[1;33m         pywrap_tf_session.TF_GraphGetOpDef(self._c_graph, compat.as_bytes(type),\n\u001b[0m\u001b[0;32m   3878\u001b[0m                                            buf)\n\u001b[0;32m   3879\u001b[0m         \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fa5f9981faff3e28c5b655bc581dda5a664ac098a4a1ee3f1bf9a902edcbe862"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}